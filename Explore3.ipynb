{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark\n",
    "\n",
    "conf = SparkConf().setAppName(\"building a warehouse\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "yelp_dir=\"/media/diego/QData/datasets/yelp\"\n",
    "\n",
    "review_file = os.path.join(yelp_dir, 'review.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business = sqlContext.read.json(business_file)\n",
    "df_review = sqlContext.read.json(review_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(business_id='ujmEBvifdJM6h6RLv4wQIg', cool=0, date='2013-05-07 04:34:36', funny=1, review_id='Q1sbwvVQXV2734tPgoKj4Q', stars=1.0, text='Total bill for this horrible service? Over $8Gs. These crooks actually had the nerve to charge us $69 for 3 pills. I checked online the pills can be had for 19 cents EACH! Avoid Hospital ERs at all costs.', useful=6, user_id='hG7b0MtEbXx5QzbzE6C_VA'),\n",
       " Row(business_id='NZnhc2sEQy3RmzKTZnqtwQ', cool=0, date='2017-01-14 21:30:33', funny=0, review_id='GJXCdrto3ASJOqKeVWPi6Q', stars=5.0, text=\"I *adore* Travis at the Hard Rock's new Kelly Cardenas Salon!  I'm always a fan of a great blowout and no stranger to the chains that offer this service; however, Travis has taken the flawless blowout to a whole new level!  \\n\\nTravis's greets you with his perfectly green swoosh in his otherwise perfectly styled black hair and a Vegas-worthy rockstar outfit.  Next comes the most relaxing and incredible shampoo -- where you get a full head message that could cure even the very worst migraine in minutes --- and the scented shampoo room.  Travis has freakishly strong fingers (in a good way) and use the perfect amount of pressure.  That was superb!  Then starts the glorious blowout... where not one, not two, but THREE people were involved in doing the best round-brush action my hair has ever seen.  The team of stylists clearly gets along extremely well, as it's evident from the way they talk to and help one another that it's really genuine and not some corporate requirement.  It was so much fun to be there! \\n\\nNext Travis started with the flat iron.  The way he flipped his wrist to get volume all around without over-doing it and making me look like a Texas pagent girl was admirable.  It's also worth noting that he didn't fry my hair -- something that I've had happen before with less skilled stylists.  At the end of the blowout & style my hair was perfectly bouncey and looked terrific.  The only thing better?  That this awesome blowout lasted for days! \\n\\nTravis, I will see you every single time I'm out in Vegas.  You make me feel beauuuutiful!\", useful=0, user_id='yXQM5uF2jS6es16SJzNHfg'),\n",
       " Row(business_id='WTqjgwHlXbSFevF32_DJVw', cool=0, date='2016-11-09 20:09:03', funny=0, review_id='2TzJjDVDEuAW6MR5Vuc1ug', stars=5.0, text=\"I have to say that this office really has it together, they are so organized and friendly!  Dr. J. Phillipp is a great dentist, very friendly and professional.  The dental assistants that helped in my procedure were amazing, Jewel and Bailey helped me to feel comfortable!  I don't have dental insurance, but they have this insurance through their office you can purchase for $80 something a year and this gave me 25% off all of my dental work, plus they helped me get signed up for care credit which I knew nothing about before this visit!  I highly recommend this office for the nice synergy the whole office has!\", useful=3, user_id='n6-Gk65cPZL6Uz8qRm3NYw'),\n",
       " Row(business_id='ikCg8xy5JIg_NGPx-MSIDA', cool=0, date='2018-01-09 20:56:38', funny=0, review_id='yi0R0Ugj_xUx_Nek0-_Qig', stars=5.0, text=\"Went in for a lunch. Steak sandwich was delicious, and the Caesar salad had an absolutely delicious dressing, with a perfect amount of dressing, and distributed perfectly across each leaf. I know I'm going on about the salad ... But it was perfect.\\n\\nDrink prices were pretty good.\\n\\nThe Server, Dawn, was friendly and accommodating. Very happy with her.\\n\\nIn summation, a great pub experience. Would go again!\", useful=0, user_id='dacAIZ6fTM6mqwW5uxkskg'),\n",
       " Row(business_id='b1b1eb3uo-w561D0ZfCEiQ', cool=0, date='2018-01-30 23:07:38', funny=0, review_id='11a8sVPMUFtaC7_ABRkmtw', stars=1.0, text='Today was my second out of three sessions I had paid for. Although my first session went well, I could tell Meredith had a particular enjoyment for her male clients over her female. However, I returned because she did my teeth fine and I was pleased with the results. When I went in today, I was in the whitening room with three other gentlemen. My appointment started out well, although, being a person who is in the service industry, I always attend to my female clientele first when a couple arrives. Unbothered by those signs, I waited my turn. She checked on me once after my original 30 minute timer to ask if I was ok. She attended my boyfriend on numerous occasions, as well as the other men, and would exit the room without even asking me or looking to see if I had any irritation. Half way through, another woman had showed up who she was explaining the deals to in the lobby. While she admits timers must be reset half way through the process, she reset my boyfriends, left, rest the gentleman furthest away from me who had time to come in, redeem his deal, get set, and gave his timer done, before me, then left, and at this point my time was at 10 minutes. So, she should have reset it 5 minutes ago, according to her. While I sat there patiently this whole time with major pain in my gums, i watched the time until the lamp shut off. Not only had she reset two others, explained deals to other guest, but she never once checked on my time. When my light turned off, I released the stance of my mouth to a more relaxed state, assuming I was only getting a thirty minute session instead of the usual 45, because she had yet to come in. At this point, the teeth formula was not only burning the gum she neglected for 25 minutes now, but it began to burn my lips. I began squealing and slapping my chair trying to get her attention from the other room in a panic. I was in so much pain, that by the time she entered the room I was already out of my chair. She finally then acknowledged me, and asked if she could put vitamin E on my gum burn (pictured below). At this point, she has treated two other gums burns, while neglecting me, and I was so irritated that I had to suffer, all I wanted was to leave. While I waited for my boyfriend, she kept harassing me about the issue. Saying, \"well burns come with teeth whitening.\" While I totally agree, and under justifiable circumstances would not be as irritate, it could have easily been avoid if she had checked on me even a second time, so I could let her know. Not only did she never check on my physical health, she couldn\\'t even take two seconds to reset the timer, which she even admitted to me. Her accuse was that she was coming in to do it, but I had the light off for a solid two minutes before I couldn\\'t stand the pain. She admitted it should be reset every 15 minutes, which means for 25 minutes she did not bother to help me at all. Her guest in the lobby then proceeded to attack me as well, simply because I wanted to leave after the way I was treated. I also expected a refund for not getting a complete session today, due to the neglect, and the fact I won\\'t be returning for my last, she had failed to do that. She was even screaming from the door, and continued to until my boyfriend and I were down the steps. I have never in my life been more appalled by a grown woman\\'s behavior, who claims to be in the business for \"10 years.\" Admit your wrongs, but don\\'t make your guest feel unwelcome because you can\\'t do you job properly.', useful=7, user_id='ssoyf2_x0EQMed6fgHeMyQ'),\n",
       " Row(business_id='eU_713ec6fTGNO4BegRaww', cool=0, date='2013-01-20 13:25:59', funny=0, review_id='fdiNeiN_hoCxCMy2wTRW9g', stars=4.0, text='I\\'ll be the first to admit that I was not excited about going to La Tavolta. Being a food snob, when a group of friends suggested we go for dinner I looked online at the menu and to me there was nothing special and it seemed overpriced.  Im also not big on ordering pasta when I go out. Alas, I was outnumbered. Thank goodness! I ordered the sea bass special. It was to die for. Cooked perfectly, seasoned perfectly, perfect portion. I can not say enough good things about this dish. When the server asked how it was he seemed very proud of the dish and said, \" doesn\\'t she (the chef) do an incredible job?\" She does. \\n\\nMy hubby got the crab tortellini and also loved his. I heard \"mmmm this is so good\" from all around the table. Our waiter was super nice and even gave us free desserts because we were some of the last people in the restaurant. Service was very slow and the place was PACKED but we had our jugs of wine and a large group with good conversation so it didn\\'t seem to bother anyone.\\n\\nSo-\\n\\nDo order the calamari and fried zucchini appetizers. Leave out the mussels. \\n\\nIf they have the sea bass special, I highly recommend it. The chicken parm and crab tortellini were also very good and very big. The chicken Romano was a bit bland. The house salads were teeny. \\n\\nDo make a reservation but still expect to wait for your food. Go with a large group of people and plan for it to be loud. Don\\'t go with a date unless you\\'re fighting and don\\'t feel like hearing anything they have to say.  Ask to sit in the side room if it\\'s available.', useful=0, user_id='w31MKYsNFMrjhWxxAb5wIw'),\n",
       " Row(business_id='3fw2X5bZYeW9xCz_zGhOHg', cool=5, date='2016-05-07 01:21:02', funny=4, review_id='G7XHMxG0bx9oBJNECG4IFg', stars=3.0, text=\"Tracy dessert had a big name in Hong Kong and the one in First Markham place has been here for many years now! \\n\\nCame in for some Chinese dessert, and I must say their selection has increased tremendously over the years. I might as well add that the price has also increased tremendously as well. The waitress gave us tea, which I could taste had red date in it. Fancy!\\n\\nA simple taro with coconut with tapioca pearls was like $5.25 or something. Basically all the desserts were more than $5. That's crazy! I can literally just make this dessert at home and for a bowl, it would probably cost like $0.50. A few years ago, I think I can still get it for like $3-$4, which is more reasonable, but wow, more than $5 is a little over the top for this dessert. Though I must say, it is Tracy Dessert, and they are a little more on the expensive side. \\n\\nI also saw other items on the menu like fish balls, chicken wings, shaved ice. My friend got a mango drink with fresh mango in it! \\n\\nI'm also surprised how many people come to Tracy Dessert after work. We came on a Sunday and the tables were always filled. I think the amount of tables they had were just perfect because no one really waited for seats for a long time, but the tables kept filling up once a table was finished.\", useful=5, user_id='jlu4CztcSxrKx56ba1a5AQ'),\n",
       " Row(business_id='zvO-PJCpNk4fgAVUnExYAA', cool=1, date='2010-10-05 19:12:35', funny=1, review_id='8e9HxxLjjqc9ez5ezzN7iQ', stars=1.0, text=\"This place has gone down hill.  Clearly they have cut back on staff and food quality\\n\\nMany of the reviews were written before the menu changed.  I've been going for years and the food quality has gone down hill.\\n\\nThe service is slow & my salad, which was $15, was as bad as it gets.\\n\\nIt's just not worth spending the money on this place when there are so many other options.\", useful=3, user_id='d6xvYpyzcfbF_AZ8vMB7QA'),\n",
       " Row(business_id='b2jN2mm9Wf3RcrZCgfo1cg', cool=0, date='2015-01-18 14:04:18', funny=0, review_id='qrffudO73zsslZbe8B9D3Q', stars=2.0, text='I was really looking forward to visiting after having some of their beers. The \"Man O\\'War\" quickly became my favorite DIPA; the Rusulka Vanilla Stout is a good thick, sweet stout; and the Ironclad is a top notch IPA. \\nThe only big miss on their beers I\\'ve had is the Big Chuck Barleywine. It could probably benefit greatly with age, but at this age all there is to taste is the alcohol.  \\nNonetheless, I had enough to convince me that the other beers I hadn\\'t had from them would be top notch... and they are! \\nThe reason for the 2 stars should not reflect the quality of the brewers, they obviously know their craft well! \\nThe servers are great and friendly.... but relying on two servers to wait on 100+ customers says a lot about how inexperienced management must be. In fact, after waiting 15 mins at a dirty table I was finally able to track down someone I guessed was an employee to let them know we were even there! \\nAfter another 5+ mins, the GM finally stopped over to take our drink order. The smugness of this guy was amazing. The thought of offering a simple apology never seemed to enter into his head. \\nThis is the time a server finally stopped by to pick up the non-final check left by the party before us... who didn\\'t seem very pleased when leaving. \\nThe toast & cheese was good, but by the time we were able to dig into their heartiest offering of food, saltines and butter may have been equally pleasing.', useful=1, user_id='sG_h0dIzTKWa3Q6fmb4u-g'),\n",
       " Row(business_id='oxwGyA17NL6c5t1Etg5WgQ', cool=1, date='2012-02-29 21:52:43', funny=0, review_id='RS_GTIT6836bCaPy637kNQ', stars=3.0, text=\"It's a giant Best Buy with 66 registers.  I don't get it.  What's the big deal about this place??\", useful=1, user_id='nMeCE5-xsdleyxYuNZ_7rA')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_and_text = df_review.select(\"stars\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def remove_punct(text):\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text)  \n",
    "    return nopunct\n",
    "\n",
    "def convert_rating(rating):\n",
    "    if rating >=4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "punct_remover = udf(lambda x: remove_punct(x))\n",
    "rating_convert = udf(lambda x: convert_rating(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF = df_review.select('review_id', punct_remover('text'), rating_convert('stars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDF = resultDF.withColumnRenamed('<lambda>(text)', 'text')\n",
    "resultDF = resultDF.withColumnRenamed('<lambda>(stars)', 'stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review_id='Q1sbwvVQXV2734tPgoKj4Q', text='Total bill for this horrible service  Over   Gs  These crooks actually had the nerve to charge us     for   pills  I checked online the pills can be had for    cents EACH  Avoid Hospital ERs at all costs ', stars='0'),\n",
       " Row(review_id='GJXCdrto3ASJOqKeVWPi6Q', text='I  adore  Travis at the Hard Rock s new Kelly Cardenas Salon   I m always a fan of a great blowout and no stranger to the chains that offer this service  however  Travis has taken the flawless blowout to a whole new level     Travis s greets you with his perfectly green swoosh in his otherwise perfectly styled black hair and a Vegas worthy rockstar outfit   Next comes the most relaxing and incredible shampoo    where you get a full head message that could cure even the very worst migraine in minutes     and the scented shampoo room   Travis has freakishly strong fingers  in a good way  and use the perfect amount of pressure   That was superb   Then starts the glorious blowout    where not one  not two  but THREE people were involved in doing the best round brush action my hair has ever seen   The team of stylists clearly gets along extremely well  as it s evident from the way they talk to and help one another that it s really genuine and not some corporate requirement   It was so much fun to be there    Next Travis started with the flat iron   The way he flipped his wrist to get volume all around without over doing it and making me look like a Texas pagent girl was admirable   It s also worth noting that he didn t fry my hair    something that I ve had happen before with less skilled stylists   At the end of the blowout   style my hair was perfectly bouncey and looked terrific   The only thing better   That this awesome blowout lasted for days    Travis  I will see you every single time I m out in Vegas   You make me feel beauuuutiful ', stars='1'),\n",
       " Row(review_id='2TzJjDVDEuAW6MR5Vuc1ug', text='I have to say that this office really has it together  they are so organized and friendly   Dr  J  Phillipp is a great dentist  very friendly and professional   The dental assistants that helped in my procedure were amazing  Jewel and Bailey helped me to feel comfortable   I don t have dental insurance  but they have this insurance through their office you can purchase for     something a year and this gave me     off all of my dental work  plus they helped me get signed up for care credit which I knew nothing about before this visit   I highly recommend this office for the nice synergy the whole office has ', stars='1'),\n",
       " Row(review_id='yi0R0Ugj_xUx_Nek0-_Qig', text='Went in for a lunch  Steak sandwich was delicious  and the Caesar salad had an absolutely delicious dressing  with a perfect amount of dressing  and distributed perfectly across each leaf  I know I m going on about the salad     But it was perfect   Drink prices were pretty good   The Server  Dawn  was friendly and accommodating  Very happy with her   In summation  a great pub experience  Would go again ', stars='1'),\n",
       " Row(review_id='11a8sVPMUFtaC7_ABRkmtw', text='Today was my second out of three sessions I had paid for  Although my first session went well  I could tell Meredith had a particular enjoyment for her male clients over her female  However  I returned because she did my teeth fine and I was pleased with the results  When I went in today  I was in the whitening room with three other gentlemen  My appointment started out well  although  being a person who is in the service industry  I always attend to my female clientele first when a couple arrives  Unbothered by those signs  I waited my turn  She checked on me once after my original    minute timer to ask if I was ok  She attended my boyfriend on numerous occasions  as well as the other men  and would exit the room without even asking me or looking to see if I had any irritation  Half way through  another woman had showed up who she was explaining the deals to in the lobby  While she admits timers must be reset half way through the process  she reset my boyfriends  left  rest the gentleman furthest away from me who had time to come in  redeem his deal  get set  and gave his timer done  before me  then left  and at this point my time was at    minutes  So  she should have reset it   minutes ago  according to her  While I sat there patiently this whole time with major pain in my gums  i watched the time until the lamp shut off  Not only had she reset two others  explained deals to other guest  but she never once checked on my time  When my light turned off  I released the stance of my mouth to a more relaxed state  assuming I was only getting a thirty minute session instead of the usual     because she had yet to come in  At this point  the teeth formula was not only burning the gum she neglected for    minutes now  but it began to burn my lips  I began squealing and slapping my chair trying to get her attention from the other room in a panic  I was in so much pain  that by the time she entered the room I was already out of my chair  She finally then acknowledged me  and asked if she could put vitamin E on my gum burn  pictured below   At this point  she has treated two other gums burns  while neglecting me  and I was so irritated that I had to suffer  all I wanted was to leave  While I waited for my boyfriend  she kept harassing me about the issue  Saying   well burns come with teeth whitening   While I totally agree  and under justifiable circumstances would not be as irritate  it could have easily been avoid if she had checked on me even a second time  so I could let her know  Not only did she never check on my physical health  she couldn t even take two seconds to reset the timer  which she even admitted to me  Her accuse was that she was coming in to do it  but I had the light off for a solid two minutes before I couldn t stand the pain  She admitted it should be reset every    minutes  which means for    minutes she did not bother to help me at all  Her guest in the lobby then proceeded to attack me as well  simply because I wanted to leave after the way I was treated  I also expected a refund for not getting a complete session today  due to the neglect  and the fact I won t be returning for my last  she had failed to do that  She was even screaming from the door  and continued to until my boyfriend and I were down the steps  I have never in my life been more appalled by a grown woman s behavior  who claims to be in the business for     years   Admit your wrongs  but don t make your guest feel unwelcome because you can t do you job properly ', stars='0'),\n",
       " Row(review_id='fdiNeiN_hoCxCMy2wTRW9g', text='I ll be the first to admit that I was not excited about going to La Tavolta  Being a food snob  when a group of friends suggested we go for dinner I looked online at the menu and to me there was nothing special and it seemed overpriced   Im also not big on ordering pasta when I go out  Alas  I was outnumbered  Thank goodness  I ordered the sea bass special  It was to die for  Cooked perfectly  seasoned perfectly  perfect portion  I can not say enough good things about this dish  When the server asked how it was he seemed very proud of the dish and said    doesn t she  the chef  do an incredible job   She does    My hubby got the crab tortellini and also loved his  I heard  mmmm this is so good  from all around the table  Our waiter was super nice and even gave us free desserts because we were some of the last people in the restaurant  Service was very slow and the place was PACKED but we had our jugs of wine and a large group with good conversation so it didn t seem to bother anyone   So   Do order the calamari and fried zucchini appetizers  Leave out the mussels    If they have the sea bass special  I highly recommend it  The chicken parm and crab tortellini were also very good and very big  The chicken Romano was a bit bland  The house salads were teeny    Do make a reservation but still expect to wait for your food  Go with a large group of people and plan for it to be loud  Don t go with a date unless you re fighting and don t feel like hearing anything they have to say   Ask to sit in the side room if it s available ', stars='1'),\n",
       " Row(review_id='G7XHMxG0bx9oBJNECG4IFg', text='Tracy dessert had a big name in Hong Kong and the one in First Markham place has been here for many years now    Came in for some Chinese dessert  and I must say their selection has increased tremendously over the years  I might as well add that the price has also increased tremendously as well  The waitress gave us tea  which I could taste had red date in it  Fancy   A simple taro with coconut with tapioca pearls was like       or something  Basically all the desserts were more than     That s crazy  I can literally just make this dessert at home and for a bowl  it would probably cost like        A few years ago  I think I can still get it for like        which is more reasonable  but wow  more than    is a little over the top for this dessert  Though I must say  it is Tracy Dessert  and they are a little more on the expensive side    I also saw other items on the menu like fish balls  chicken wings  shaved ice  My friend got a mango drink with fresh mango in it    I m also surprised how many people come to Tracy Dessert after work  We came on a Sunday and the tables were always filled  I think the amount of tables they had were just perfect because no one really waited for seats for a long time  but the tables kept filling up once a table was finished ', stars='0'),\n",
       " Row(review_id='8e9HxxLjjqc9ez5ezzN7iQ', text='This place has gone down hill   Clearly they have cut back on staff and food quality  Many of the reviews were written before the menu changed   I ve been going for years and the food quality has gone down hill   The service is slow   my salad  which was      was as bad as it gets   It s just not worth spending the money on this place when there are so many other options ', stars='0'),\n",
       " Row(review_id='qrffudO73zsslZbe8B9D3Q', text='I was really looking forward to visiting after having some of their beers  The  Man O War  quickly became my favorite DIPA  the Rusulka Vanilla Stout is a good thick  sweet stout  and the Ironclad is a top notch IPA   The only big miss on their beers I ve had is the Big Chuck Barleywine  It could probably benefit greatly with age  but at this age all there is to taste is the alcohol    Nonetheless  I had enough to convince me that the other beers I hadn t had from them would be top notch    and they are   The reason for the   stars should not reflect the quality of the brewers  they obviously know their craft well   The servers are great and friendly     but relying on two servers to wait on      customers says a lot about how inexperienced management must be  In fact  after waiting    mins at a dirty table I was finally able to track down someone I guessed was an employee to let them know we were even there   After another    mins  the GM finally stopped over to take our drink order  The smugness of this guy was amazing  The thought of offering a simple apology never seemed to enter into his head   This is the time a server finally stopped by to pick up the non final check left by the party before us    who didn t seem very pleased when leaving   The toast   cheese was good  but by the time we were able to dig into their heartiest offering of food  saltines and butter may have been equally pleasing ', stars='0'),\n",
       " Row(review_id='RS_GTIT6836bCaPy637kNQ', text='It s a giant Best Buy with    registers   I don t get it   What s the big deal about this place  ', stars='0'),\n",
       " Row(review_id='kbtscdyz6lvrtGjD1quQTg', text='Like walking back in time  every Saturday morning my sister and I was in a bowling league and after we were done  we d spend a few quarters playing the pin ball machines until our mother came to pick us up   My sister was daring and play the machines hard  she was afraid of that  tilt  showing up and freezing the game   I  on the other hand was a bit more gentler and wanted to make sure I got my quarter s worth   This place has rows and rows of machines  some are really old and some are more of a mid    s theme   There is even a Ms pac man   It was fun to spend an afternoon playing the machines and remembering all the fun of my early teen years ', stars='1'),\n",
       " Row(review_id='-I5umRTkhw15RqpKMl_o1Q', text='Walked in around   on a Friday afternoon  we sat at a table just off the bar and walked out after   min or so  Don t even think they realized we walked in  However everyone at the bar noticed we walked in    Service was non existent at best  Not a good way for a new business to start out  Oh well  the location they are at has been about   different things over the past several years  so they will just be added to the list  SMDH   ', stars='0'),\n",
       " Row(review_id='Z7wgXp98wYB57QdRY3HQ3w', text='Wow  So surprised at the one and two star reviews   We started with the most tender calamari  Although the marinara sauce was a bit bland  but a touch of salt made it just right  My husband had the veal with peppers and said it was so delicious and tender  The mashed potatoes were perfect  I had the salmon Diablo which was also delicious  Our salad was beautiful  Dressing was served on the salad and it was a nice amount  We ended our delicious meal with a piece of tiramisu  Our server Matt was right on   Very pleasant and knowledgeable about the menu  Our appetizer  salad and entrees were timed perfectly  I love salad and did not mind that my entree was served while I was still eating it  No problem it let my dinner cool to just the right temp for me to eat it comfortably   I wonder sometimes if people just don t appreciate relaxing and taking time to eat a wonderful and beautifully prepared meal   A wonderful atmosphere  So relaxing  The chairs are super comfortable too    We will certainly be back   Give it a try   Don t  always go by the reviews   A bottle of Riesling  calamari app  two delicious entrees and dessert for       Well with it ', stars='1'),\n",
       " Row(review_id='qlXw1JQ0UodW7qrmVgwCXw', text='Michael from Red Carpet VIP is amazing   I reached out because I needed help planning my soon to be sister in law s bachelorette  It was a group of    girls so I was a little overwhelmed but Michael saved the day  Everything was super smooth and easy  We got good deals and had the best time ever  We booked hotel and a bachelorette package for a great price  I have saved contact info because I will for sure reach out again on next Vegas trip   ', stars='1'),\n",
       " Row(review_id='JVcjMhlavKKn3UIt9p9OXA', text='I cannot believe how things have changed in   years  I picked up duck congee sometime in the winter when my hubby was sick   I was very disappointed because the ginger fish sauce tasted like it had gone bad  it should never be bitter    Today  my hubby wanted to eat there since he was craving the duck congee and most places don t serve the duck   coleslaw side  We waited about    minutes to get our menu   After we placed our orders  we waited another   minutes to get the tea that most places bring with the menu   I could go on with the details but the gist of the story is they were understaffed or the staff was slow   The worst part of it was that the service   The servers make us feel bad for asking for anything  like when they took our order    We had arrived and placed our order before another couple bside us at least    minutes ahead but somehow  this couple received their pho before mine   They were almost done eating their pho before mine came out ', stars='0'),\n",
       " Row(review_id='svK3nBU7Rk8VfGorlrN52A', text='You can t really find anything wrong with this place  the pastas and pizzas are both amazing and high quality  the price is very reasonable  the owner and the staff are very friendly  if you re in downtown check this place out  a lot of people think just because it s downtown there are lots of options around but that s not always the case as there is also a lot of poor quality food in downtown as well ', stars='1'),\n",
       " Row(review_id='1wVA2-vQIuW_ClmXkDxqMQ', text='Great lunch today  Staff was very helpful in assisting with selections and knowledgeable on the ingredients  We enjoyed the BBQ chicken with tika masala sauce and really good naan bread  The biryani with chicken was also yummy  Fun to see the food being prepared in the tandoori ovens  Great addition to the fast casual scene in Cleveland ', stars='1'),\n",
       " Row(review_id='6BnQwlxRn7ZuWdzninM9sQ', text='I love chinese food and I love mexican food  What can go wrong  A couple of things  First things first  this place is more of a  rice bowl  kind of place  I thought it was going to be more diverse as far as the menu goes  but its mainly rice bowls you get with different kinds of meats  The ordering was a little confusing at first  but one of the employees helped us out and I got the   item bowl and got the jade chicken and hengrenade chicken with all rice jerk   I also ordered a jade chicken quesadilla on the side   I m gonna admit  this place looks kinda dirty  I don t think Arizona uses those health department letter grade system like California does  but if I were to just judge by how it looked inside  i d give it a  C  grade lol  We waited for about    minutes or so and finally got our food  We took it to go and ate at our hotel room    Mmmm    the food was just alright  The jade chicken was nothing special  It tasted like any generic chinese fast food orange chicken sesame chicken variant  The hengrenade chicken  although was the less spicier version of the jerk chicken  was still pretty spicy for me  Just be warned the jerk chicken is super spicy  If you aren t sure  ask for a sample at the restaurant before ordering  but it was way too spicy for me    The jade chicken quesadilla was decent  but nothing special  Just imagine orange chicken in between a tortilla and cheese  A friend of mine ordered a jade chicken burrito and we were confused when we pulled it out of the bag because it was literally the size of Mcdonald s apple pie  If you order the burrito  be warned that it s a burrito for gnomes and smurfs  but he said it was tasty    They provide a snicker doodle sugar cookie for each meal and it was decent  again nothing special    Not gonna lie  the next day my stomach felt like a little mexican dude and chinese dude were wrestling and throwing molotov cocktails inside  I used the bathroom like   times  I don t recommend eating this place if you have a lot to do the next day ', stars='0'),\n",
       " Row(review_id='rEITo90tpyKmEfNDp3Ou3A', text='We ve been a huge Slim s fan since they opened one up in Texas about two years ago when we used to live there  This place never disappoints  They even have great salads and grilled chicken  Plus they have fresh brewed sweet tea  it s the best ', stars='1'),\n",
       " Row(review_id='4bUyL7lzoWzDZaJETAKREg', text='Good selection of classes of beers and mains  I ve been here twice   First time I had the fried chicken  It was delicious  but be warned  extremely salty  I couldn t even finish the last piece of chicken after experiencing a salt overload   Second time we came on a wednesday  We didn t know it was BBQ night  where they have a completely different menu  and don t offer anything from their original vegetarian friendly menu  This menu has one vegetarian friendly option   an eggplant sandwich  The vegetarian in my party said it was awful  Also  on BBQ night you choose   sides  Except they were out of all their sides except     fries and potato salad  I can t say I was thrilled to have carb heavy sides with my carb heavy main  How do you run out of sides so early in the evening   Service not so great   I d avoid coming here on wednesdays ', stars='0'),\n",
       " Row(review_id='Amo5gZBvCuPc_tZNpHwtsA', text='Our family LOVES the food here  Quick  friendly  delicious  and a great restaurant to take kids to    stars ', stars='1'),\n",
       " Row(review_id='IPw8yWiyqnfBzzWmypUHgg', text='If you are looking for the best pierogies in Pittsburgh  this is your place  There are a few small tables outside but most of the business is carry out  Pierogies Plus wins Best Pierogies every year  Why  Because the owner is from Poland and she is making the real deal pierogies  The best part is that they are hand pinched by a group of older Polish and Hungarian women   The biggest seller is potato and cheese but they sell many flavors  They are like plump pillows of softness  You can buy them buy the dozen  You can get them cold to take home and freeze or warm and ready to eat  The warm ones are served with butter and onions   It s definitely a comfort food  The best part is that they ship internationally  Yes  they are that good ', stars='1'),\n",
       " Row(review_id='IByf6mVY0WA838XNSh-5MA', text='The food is always good and the prices are reasonable   Although it s not exactly a restaurant    more like a snack bar  limited menu and you walk up to the counter  place your order  wait a minute or so for them to prepare your order  and pay the cashier  then search for a table   Kind of like a sandwich shop   Still a much better choice for value than the other hotel Deli s on the strip ', stars='1'),\n",
       " Row(review_id='S337tATeouQJdoPYyir29w', text='Pick any meat on the planet and the chef will make a Mexican style dish with amazing flavor  Wow  fish and lamb tacos to die for  Drinks are great as well ', stars='1'),\n",
       " Row(review_id='D_UvaenM25iNd6aehTZ0MA', text='Great food  great service  Obviously fried chicken isn t the healthiest food on earth  but once a month I get that craving for good fried chicken  Their chicken is great  doesn t seem too fatty  and their sides are excellent too  A ', stars='1'),\n",
       " Row(review_id='I9HBDyzCqLhTYHCAZIFZQQ', text='PlumbSmart provided superior service from beginning to end   They were able to repair a badly damaged sewer pipe with only one day s notice   I was particularly pleased with their attention to care when cleaning up the landscape after the job was completed   Their competitive pricing and excellent service make them my first stop for all future plumbing needs   Thank you to Wayne and the whole team    Scott B', stars='1'),\n",
       " Row(review_id='W1wbNaUnbMy4b9QqY3_SAg', text='Unfortunately  I must recommend not to conduct any business with Fast Fix Jewelry and Watch Repairs   The staff is completely unprofessional and I have never been treated so rudely in my life   I was actually shocked and walked away thinking  wow  how do those people even have a job    I have never written a negative review before  I usually chalk it up to someone having a bad day   I have worked in customer service for     years and I know it is exhausting and bad days happen   But this is a special occasion   I drove    minutes to try to find someone who could help me repair a watch band   I was barely greeted upon arrival and right away felt like I was bothering them   The girl behind the counter obviously just wanted me to leave  the blond kid working snapped at me when I asked a question and when I re asked in order to clarify what he said he snapped again and said   I already told you       Is this even authentic    Shouting at me over his shoulder as he work on something else    I was shocked and just stood there put my watch away awkwardly and left with no one else saying a word to me   There are a lot of places that fix Jewelry in this city and I will be taking my business elsewhere and recommend that people reading this review do the same   Some places  just do not deserve a loyal customer base ', stars='0'),\n",
       " Row(review_id='qm97yMwREr7BKkexlwLFbg', text='their pettuccine was fresh made in the morning  it was very delicate and yummy  the owner and staffs are super kind and delightful  We also had Veal piccata  it was classic  love this restaurant ', stars='1'),\n",
       " Row(review_id='1daGBpea0sleayFeeXuoYw', text='if i can give this place no stars i would  i only had their hot pot though  so im not a good judge for anything besides their shabu  i must say  quantity was small  price is expensive for the quality and quantity  and the taste of the soup base is bland as if they just put hot water in  the sauce selection is limited and not very fresh clean from my perspective  i love hot pot and i would never go back again because home made hot pot can be much better than this place without even trying  anyways  if you have a good appetite for hot pot  you can do yourself a favor and skip this place because it can make you miserable ', stars='0'),\n",
       " Row(review_id='DAC4zWY2ZMa1vxpN9RrDvA', text='This review is in regards to our experience watching SuperBowl    February         at the WestGate in the theater auditorium   Watch the game somewhere else       To those unfamiliar with The Big Game experience at WestGate you typically would get in line to watch the Superbowl in the theater portion of the hotel around   am on Superbowl Sunday  This line can get extremely long yet the earlier you get in line your choice of seating significantly improves So   after waiting in line for a few hours we were notified the lower portion of the theater was reserved for paid customers who previously purchased wristbands for       including alcohol and hot dogs  and instead we would be seated in the balcony portion of the theater No problem  something different  we said  Mistake   So at      pm we were sent upstairs to the balcony to take our seats and prepare to watch the big game at       Once we take our seats one of us   we re in a group of     will hold the seats while the rest of us will go out to the casino floor and gamble or go the the sports book and place a couple last minute bets Please note the patrons that leave the auditorium will receive a hand stamp or wristband to allow reentry to the theater  BUT INSTEAD      We were told by Westgate staff that no hand stamps or wristbands would be given and we were ON OUR OWN if we choose to leave and we would not be allowed back in  Wow  That s right  after waiting in line all morning if we wanted to go downstairs to play blackjack  place a bet at the book  or maybe have a bite to eat because no food was made available upstairs we would be out of luck  Nice work Westgate   So we were seated upstairs   stuck  With no food or soda available for purchase  Only beer and water was sold in the balcony food counter  That was at      p m  After vigorously complaining to Westgate staff   to ushers with yellow jackets and security with black jackets   at      pm wristbands were given out  At      hot dogs and soda were made available for sale in the balcony  I believe this was a direct result of all the upset patrons like myself that were seated in the balcony level   In summary  for being the biggest sportbook in Las Vegas this place is dysfunction and fails to satisfy the most basic request to provide food and comfort to betting patrons  A total mess  This place sucks  Watch the big game and bet your money some where else  We will ', stars='0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import *\n",
    "\n",
    "#tokenizer and stop word remover\n",
    "tok = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "#stop word remover\n",
    "stopwordrm = StopWordsRemover(inputCol='words', outputCol='words_nsw')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# Build the pipeline \n",
    "pipeline = Pipeline(stages=[tok, stopwordrm])\n",
    "# Fit the pipeline \n",
    "review_tokenized = pipeline.fit(resultDF).transform(resultDF).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o120.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 6.0 failed 1 times, most recent failure: Lost task 4.0 in stage 6.0 (TID 95, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:157)\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:71)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder$class.appendFrom(NullableColumnBuilder.scala:61)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:109)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:84)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:764)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:69)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1168)\n\tat org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:230)\n\tat org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:149)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:157)\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:71)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder$class.appendFrom(NullableColumnBuilder.scala:61)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:109)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:84)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:764)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:69)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2e873b0fc5a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# count vectorizer and tfidf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcv_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ngram'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf_ngram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcvModel_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcv_df_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvModel_ngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o120.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 6.0 failed 1 times, most recent failure: Lost task 4.0 in stage 6.0 (TID 95, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:157)\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:71)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder$class.appendFrom(NullableColumnBuilder.scala:61)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:109)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:84)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:764)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:69)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1168)\n\tat org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:230)\n\tat org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:149)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:57)\n\tat java.nio.ByteBuffer.allocate(ByteBuffer.java:335)\n\tat org.apache.spark.sql.execution.columnar.ColumnBuilder$.ensureFreeSpace(ColumnBuilder.scala:157)\n\tat org.apache.spark.sql.execution.columnar.BasicColumnBuilder.appendFrom(ColumnBuilder.scala:71)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.org$apache$spark$sql$execution$columnar$NullableColumnBuilder$$super$appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.NullableColumnBuilder$class.appendFrom(NullableColumnBuilder.scala:61)\n\tat org.apache.spark.sql.execution.columnar.ComplexColumnBuilder.appendFrom(ColumnBuilder.scala:91)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:109)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anonfun$1$$anon$1.next(InMemoryRelation.scala:84)\n\tat org.apache.spark.storage.memory.PartiallyUnrolledIterator.next(MemoryStore.scala:764)\n\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1174)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1$$anonfun$apply$7.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:69)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1172)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "\n",
      "Exception happened during processing of request from ('127.0.0.1', 42112)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/accumulators.py\", line 269, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/diego/anaconda3/envs/pyspark_env/lib/python3.7/site-packages/pyspark/serializers.py\", line 717, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# add ngram column\n",
    "n = 3\n",
    "ngram = NGram(inputCol = 'words', outputCol = 'ngram', n = n)\n",
    "add_ngram = ngram.transform(review_tokenized)\n",
    "\n",
    "# count vectorizer and tfidf\n",
    "cv_ngram = CountVectorizer(inputCol='ngram', outputCol='tf_ngram')\n",
    "cvModel_ngram = cv_ngram.fit(add_ngram)\n",
    "cv_df_ngram = cvModel_ngram.transform(add_ngram)\n",
    "\n",
    "# create TF-IDF matrix\n",
    "idf_ngram = IDF().setInputCol('tf_ngram').setOutputCol('tfidf_ngram')\n",
    "tfidfModel_ngram = idf_ngram.fit(cv_df_ngram)\n",
    "tfidf_df_ngram = tfidfModel_ngram.transform(cv_df_ngram)\n",
    "\n",
    "# split into training & testing set\n",
    "splits_ngram = tfidf_df_ngram.select(['tfidf_ngram', 'label']).randomSplit([0.8,0.2],seed=100)\n",
    "train_ngram = splits_ngram[0].cache()\n",
    "test_ngram = splits_ngram[1].cache()\n",
    "\n",
    "# Convert feature matrix to LabeledPoint vectors\n",
    "train_lb_ngram = train_ngram.rdd.map(lambda row: LabeledPoint(row[1], MLLibVectors.fromML(row[0])))\n",
    "test_lb_ngram = train_ngram.rdd.map(lambda row: LabeledPoint(row[1], MLLibVectors.fromML(row[0])))\n",
    "\n",
    "# fit SVM model of only trigrams\n",
    "numIterations = 50\n",
    "regParam = 0.3\n",
    "svm = SVMWithSGD.train(train_lb_ngram, numIterations, regParam=regParam)\n",
    "\n",
    "#extract top 20 trigrams based on weights\n",
    "top_ngram = svm_coeffs_df_ngram.sort_values('weight')['ngram'].values[:20]\n",
    "bottom_ngram = svm_coeffs_df_ngram.sort_values('weight', ascending=False)['ngram'].values[:20]\n",
    "ngram_list = list(top_ngram) + list(bottom_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the word with selected ngram\n",
    "def ngram_concat(text):\n",
    "    text1 = text.lower()\n",
    "    for ngram in ngram_list:\n",
    "        if ngram in text1:\n",
    "            new_ngram = ngram.replace(' ', '_')\n",
    "            text1 = text1.replace(ngram, new_ngram)\n",
    "    return text1\n",
    "\n",
    "ngram_df = udf(lambda x: ngram_concat(x))\n",
    "ngram_df = review_tokenized.select(ngram_df('text'), 'label')\\\n",
    "                          .withColumnRenamed('<lambda>(text)', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer and tfidf\n",
    "cv = CountVectorizer(inputCol='words_nsw', outputCol='tf')\n",
    "cvModel = cv.fit(review_tokenized)\n",
    "count_vectorized = cvModel.transform(review_tokenized)\n",
    "\n",
    "tfidfModel = idf.fit(count_vectorized)\n",
    "tfidf_df = tfidfModel.transform(count_vectorized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
